{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71ba1836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "import os, time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72dbe208",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">usual-glitter-4</strong> at: <a href='https://wandb.ai/142402007-indian-institute-of-technology-palakkad/Kundan_ass_6/runs/i20oey98' target=\"_blank\">https://wandb.ai/142402007-indian-institute-of-technology-palakkad/Kundan_ass_6/runs/i20oey98</a><br> View project at: <a href='https://wandb.ai/142402007-indian-institute-of-technology-palakkad/Kundan_ass_6' target=\"_blank\">https://wandb.ai/142402007-indian-institute-of-technology-palakkad/Kundan_ass_6</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251110_222400-i20oey98/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sumanp/Assignment-5/wandb/Kundan_assign_6/wandb/run-20251110_222413-25weoali</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/142402007-indian-institute-of-technology-palakkad/Kundan_ass_6/runs/25weoali' target=\"_blank\">skilled-music-5</a></strong> to <a href='https://wandb.ai/142402007-indian-institute-of-technology-palakkad/Kundan_ass_6' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/142402007-indian-institute-of-technology-palakkad/Kundan_ass_6' target=\"_blank\">https://wandb.ai/142402007-indian-institute-of-technology-palakkad/Kundan_ass_6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/142402007-indian-institute-of-technology-palakkad/Kundan_ass_6/runs/25weoali' target=\"_blank\">https://wandb.ai/142402007-indian-institute-of-technology-palakkad/Kundan_ass_6/runs/25weoali</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# Replace this with your actual API key\n",
    "wandb.login(key=\"\")\n",
    "\n",
    "wandb.init(project=\"Kundan_ass_6\", config={\n",
    "    \"epochs\": 20,\n",
    "    \"batch_size\": 256,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"model\": \"ResNet18\",\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"img_size\": 128\n",
    "})\n",
    "\n",
    "config = wandb.config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a05c1cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation folder already organized.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "data_dir = \"/home/sumanp/Assignment-5/wandb/Kundan_assign_6/tiny-imagenet-200\"\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "val_dir   = os.path.join(data_dir, \"val\")\n",
    "val_img_dir = os.path.join(val_dir, \"images\")\n",
    "val_annot_file = os.path.join(val_dir, \"val_annotations.txt\")\n",
    "\n",
    "if os.path.exists(val_img_dir) and os.path.exists(val_annot_file):\n",
    "    print(\"Organizing validation folder...\")\n",
    "    with open(val_annot_file, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) >= 2:\n",
    "                img, cls = parts[0], parts[1]\n",
    "                cls_folder = os.path.join(val_dir, cls)\n",
    "                os.makedirs(cls_folder, exist_ok=True)\n",
    "                src = os.path.join(val_img_dir, img)\n",
    "                dst = os.path.join(cls_folder, img)\n",
    "                if os.path.exists(src) and not os.path.exists(dst):\n",
    "                    shutil.copy(src, dst)\n",
    "    print(\"‚úÖ Validation folder organized successfully.\")\n",
    "else:\n",
    "    print(\"Validation folder already organized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bf96a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Train samples: 100000 | Val samples: 10000 | Classes: 200\n"
     ]
    }
   ],
   "source": [
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std  = [0.229, 0.224, 0.225]\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(config.img_size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=imagenet_mean, std=imagenet_std)\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize(config.img_size),\n",
    "    transforms.CenterCrop(config.img_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=imagenet_mean, std=imagenet_std)\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(train_dir, transform=transform_train)\n",
    "val_data   = datasets.ImageFolder(val_dir,   transform=transform_val)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=config.batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader   = DataLoader(val_data,   batch_size=config.batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "print(f\"‚úÖ Train samples: {len(train_data)} | Val samples: {len(val_data)} | Classes: {len(train_data.classes)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "153451ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No extra folder found.\n",
      "‚úÖ Validation dataset reloaded. Classes: 200\n"
     ]
    }
   ],
   "source": [
    "import shutil, os\n",
    "\n",
    "# Path to your validation directory\n",
    "val_dir = \"/home/sumanp/Assignment-5/wandb/Kundan_assign_6/tiny-imagenet-200/val\"\n",
    "# Remove leftover 'images' folder if it exists\n",
    "bad_folder = os.path.join(val_dir, \"images\")\n",
    "if os.path.exists(bad_folder):\n",
    "    shutil.rmtree(bad_folder)\n",
    "    print(\"‚úÖ Removed extra folder:\", bad_folder)\n",
    "else:\n",
    "    print(\"No extra folder found.\")\n",
    "\n",
    "# Reload validation dataset\n",
    "from torchvision import datasets\n",
    "\n",
    "val_data = datasets.ImageFolder(val_dir, transform=transform_val)\n",
    "val_loader = DataLoader(val_data, batch_size=config.batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "print(f\"‚úÖ Validation dataset reloaded. Classes: {len(val_data.classes)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76601540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sumanp/miniconda3/envs/awa2/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/sumanp/miniconda3/envs/awa2/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model ready for training\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze backbone\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace final FC layer for 200 Tiny ImageNet classes\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 200)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=config.learning_rate)\n",
    "\n",
    "print(\"‚úÖ Model ready for training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "951508bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [00:34<00:00, 11.36it/s]\n",
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 -> TrainAcc: 32.05% | ValAcc: 50.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Best model updated (Val Acc: 50.69%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [00:32<00:00, 12.01it/s]\n",
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 -> TrainAcc: 41.25% | ValAcc: 52.92%\n",
      "‚úÖ Best model updated (Val Acc: 52.92%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [00:33<00:00, 11.65it/s]\n",
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 -> TrainAcc: 42.72% | ValAcc: 53.56%\n",
      "‚úÖ Best model updated (Val Acc: 53.56%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [00:33<00:00, 11.77it/s]\n",
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 -> TrainAcc: 43.26% | ValAcc: 53.87%\n",
      "‚úÖ Best model updated (Val Acc: 53.87%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [00:32<00:00, 12.02it/s]\n",
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 -> TrainAcc: 43.45% | ValAcc: 54.31%\n",
      "‚úÖ Best model updated (Val Acc: 54.31%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [00:32<00:00, 11.88it/s]\n",
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 -> TrainAcc: 44.21% | ValAcc: 54.32%\n",
      "‚úÖ Best model updated (Val Acc: 54.32%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [00:33<00:00, 11.73it/s]\n",
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 -> TrainAcc: 44.24% | ValAcc: 54.46%\n",
      "‚úÖ Best model updated (Val Acc: 54.46%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [00:32<00:00, 11.88it/s]\n",
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 -> TrainAcc: 44.28% | ValAcc: 54.59%\n",
      "‚úÖ Best model updated (Val Acc: 54.59%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [00:33<00:00, 11.80it/s]\n",
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 -> TrainAcc: 44.41% | ValAcc: 55.26%\n",
      "‚úÖ Best model updated (Val Acc: 55.26%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [00:33<00:00, 11.55it/s]\n",
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 -> TrainAcc: 44.78% | ValAcc: 54.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [00:34<00:00, 11.44it/s]\n",
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 -> TrainAcc: 44.85% | ValAcc: 54.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [00:34<00:00, 11.41it/s]\n",
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 -> TrainAcc: 44.78% | ValAcc: 54.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [00:32<00:00, 11.97it/s]\n",
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 -> TrainAcc: 44.80% | ValAcc: 54.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [00:32<00:00, 12.00it/s]\n",
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 -> TrainAcc: 44.85% | ValAcc: 54.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [00:34<00:00, 11.40it/s]\n",
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 -> TrainAcc: 44.84% | ValAcc: 54.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [00:33<00:00, 11.83it/s]\n",
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 -> TrainAcc: 44.87% | ValAcc: 54.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [00:34<00:00, 11.39it/s]\n",
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 -> TrainAcc: 45.04% | ValAcc: 54.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [00:33<00:00, 11.74it/s]\n",
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 -> TrainAcc: 45.17% | ValAcc: 54.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [00:32<00:00, 11.87it/s]\n",
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 -> TrainAcc: 45.06% | ValAcc: 55.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 391/391 [00:32<00:00, 11.88it/s]\n",
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 -> TrainAcc: 45.06% | ValAcc: 54.70%\n",
      "\n",
      "Training Complete ‚úÖ | Best Validation Accuracy: 55.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "best_val_acc = 0.0\n",
    "best_path = \"/home/sumanp/Assignment-5/wandb/Kundan_assign_6/model/kundan_model.pth\"\n",
    "\n",
    "for epoch in range(config.epochs):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0, 0, 0\n",
    "\n",
    "    # TRAIN LOOP\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config.epochs} - Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "\n",
    "    # VALIDATION LOOP (optimized to prevent crash)\n",
    "    model.eval()\n",
    "    val_loss, val_correct, val_total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{config.epochs} - Validating\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, preds = outputs.max(1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += preds.eq(labels).sum().item()\n",
    "\n",
    "            # clear memory after each batch\n",
    "            del images, labels, outputs, preds, loss\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    val_loss = val_loss / val_total\n",
    "    val_acc  = 100.0 * val_correct / val_total\n",
    "\n",
    "    # Log metrics to W&B\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"val_acc\": val_acc\n",
    "    })\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{config.epochs} -> TrainAcc: {train_acc:.2f}% | ValAcc: {val_acc:.2f}%\")\n",
    "\n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), best_path)\n",
    "        wandb.save(best_path)\n",
    "        print(f\"‚úÖ Best model updated (Val Acc: {val_acc:.2f}%)\")\n",
    "\n",
    "print(f\"\\nTraining Complete ‚úÖ | Best Validation Accuracy: {best_val_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7a0b6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model artifact logged to W&B\n"
     ]
    }
   ],
   "source": [
    "artifact = wandb.Artifact('kundan_model', type='model')\n",
    "artifact.add_file(best_path)\n",
    "wandb.log_artifact(artifact)\n",
    "\n",
    "print(\"‚úÖ Model artifact logged to W&B\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b93d4e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface_hub --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6700066",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Use the new user's token here (you can find it in your HF account settings)\n",
    "login(token=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b08f35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fda970303c3743cb9d499fd1c1bcc003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()  # ‚¨ÖÔ∏è This will ask for your Hugging Face token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4ed8a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Repository created: https://huggingface.co/Kundan-26/resnet18-Kundan\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi, HfFolder, Repository\n",
    "\n",
    "repo_name = \"resnet18-Kundan\"\n",
    "user = HfApi().whoami()[\"name\"]\n",
    "repo_id = f\"{user}/{repo_name}\"\n",
    "\n",
    "# Create repo on your HF account (skip if it already exists)\n",
    "HfApi().create_repo(repo_id=repo_id, private=False, exist_ok=True)\n",
    "print(f\"‚úÖ Repository created: https://huggingface.co/{repo_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09b69e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os\n",
    "\n",
    "repo_name = \"resnet18-Kundan\"\n",
    "user = \"Kundan-26\"   \n",
    "repo_id = f\"{user}/{repo_name}\"\n",
    "\n",
    "model_save_dir = f\"/home/sumanp/Assignment-5/wandb/Kundan_assign_6/{repo_name}\"\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "# ‚úÖ Save model weights\n",
    "torch.save(model.state_dict(), f\"{model_save_dir}/pytorch_model.bin\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cb41b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_USER\"] = \"Kundan-26\"                       \n",
    "os.environ[\"SPACE_NAME\"] = \"resnet18-Kundan-app\"      \n",
    "os.environ[\"HF_TOKEN\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "451bb7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import gradio as gr\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load label names (Tiny ImageNet classes)\n",
    "label_file = \"wnids.txt\"  # optional file with class IDs if you have it\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"Running on CPU\")\n",
    "\n",
    "# Build label list (1-200 if wnids.txt not available)\n",
    "if not hasattr(__builtins__, 'open'):\n",
    "    open = __builtins__.open\n",
    "try:\n",
    "    with open(label_file) as f:\n",
    "        idx_to_class = [line.strip() for line in f.readlines()]\n",
    "except FileNotFoundError:\n",
    "    idx_to_class = [f\"class_{i}\" for i in range(200)]\n",
    "\n",
    "# Load model\n",
    "model = models.resnet18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 200)\n",
    "model.load_state_dict(torch.load(\"pytorch_model.bin\", map_location=\"cpu\"))\n",
    "model.eval()\n",
    "\n",
    "# Preprocess\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.CenterCrop(128),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "# Prediction function\n",
    "def predict(img):\n",
    "    img = transform(img).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img)\n",
    "        pred = torch.argmax(outputs, dim=1).item()\n",
    "    label = idx_to_class[pred] if pred < len(idx_to_class) else str(pred)\n",
    "    return f\" Predicted: {label}\"\n",
    "\n",
    "# Build interface\n",
    "demo = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=gr.Image(type=\"pil\", label=\"Upload Tiny ImageNet Image\"),\n",
    "    outputs=gr.Textbox(label=\"Prediction\"),\n",
    "    title=\" ResNet18 Tiny ImageNet Classifier\",\n",
    "    description=\"Upload an image and get the predicted class name.\"\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "209472b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "torch\n",
    "torchvision\n",
    "gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7555f7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Space: https://huggingface.co/spaces/Kundan-26/resnet18-Kundan-app\n",
      "Preparing upload folder: /tmp/hf_space_8gpwg9qe\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb087f2cbbf4ec98265417985a97059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e14006286744450c813ce955acf09224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded files: ['/home/sumanp/Assignment-5/wandb/Kundan_assign_6/app.py', '/home/sumanp/Assignment-5/wandb/Kundan_assign_6/requirements.txt', '/home/sumanp/Assignment-5/wandb/Kundan_assign_6/resnet18-Kundan/pytorch_model.bin']\n",
      "‚úÖ App deployed successfully at: https://huggingface.co/spaces/Kundan-26/resnet18-Kundan-app\n"
     ]
    }
   ],
   "source": [
    "import os, shutil, tempfile\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "token = os.environ.get(\"HF_TOKEN\")\n",
    "user = os.environ.get(\"HF_USER\")\n",
    "space = os.environ.get(\"SPACE_NAME\")\n",
    "if not token or not user or not space:\n",
    "    raise RuntimeError(\"HF_TOKEN, HF_USER or SPACE_NAME not set in environment.\")\n",
    "\n",
    "api = HfApi(token=token)\n",
    "repo_id = f\"{user}/{space}\"\n",
    "\n",
    "repo_url = api.create_repo(repo_id=repo_id, repo_type=\"space\", space_sdk=\"gradio\", exist_ok=True)\n",
    "print(\"Using Space:\", repo_url)\n",
    "\n",
    "tmpdir = tempfile.mkdtemp(prefix=\"hf_space_\")\n",
    "print(\"Preparing upload folder:\", tmpdir)\n",
    "\n",
    "# copy notebook artifacts into tmpdir\n",
    "cwd = os.getcwd()\n",
    "copied = []\n",
    "for fname in (\"app.py\", \"requirements.txt\"):\n",
    "    src = os.path.join(cwd, fname)\n",
    "    if os.path.exists(src):\n",
    "        shutil.copy(src, tmpdir)\n",
    "        copied.append(src)\n",
    "    else:\n",
    "        print(f\"Warning: {src} not found, skipping.\")\n",
    "\n",
    "# copy model file from model_save_dir\n",
    "model_bin = os.path.join(model_save_dir, \"pytorch_model.bin\")\n",
    "if os.path.exists(model_bin):\n",
    "    shutil.copy(model_bin, tmpdir)\n",
    "    copied.append(model_bin)\n",
    "else:\n",
    "    print(f\"Warning: {model_bin} not found, skipping.\")\n",
    "\n",
    "if not copied:\n",
    "    raise RuntimeError(\"No files found to upload. Ensure app.py, requirements.txt or model exist.\")\n",
    "\n",
    "api.upload_folder(\n",
    "    folder_path=tmpdir,\n",
    "    repo_id=repo_id,\n",
    "    repo_type=\"space\",\n",
    "    commit_message=\"üöÄ Deploy ResNet18 Tiny ImageNet Gradio App\"\n",
    ")\n",
    "\n",
    "print(\"Uploaded files:\", copied)\n",
    "print(\"‚úÖ App deployed successfully at:\", repo_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "025589b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token owner: Kundan-26 | account type: user\n",
      "Attempting to create Space under: Kundan-26/resnet18-Kundan-app\n",
      "‚úÖ Space created/existed at: https://huggingface.co/spaces/Kundan-26/resnet18-Kundan-app\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic + safe retry for HF Space creation (run in new cell)\n",
    "# Uses existing `api`, `token`, and `space` variables from the notebook.\n",
    "\n",
    "try:\n",
    "    who = api.whoami()\n",
    "    owner = who.get(\"name\", \"<unknown>\")\n",
    "    print(\"Token owner:\", owner, \"| account type:\", who.get(\"type\"))\n",
    "except Exception as e:\n",
    "    print(\"Failed to call whoami():\", e)\n",
    "    owner = None\n",
    "\n",
    "if owner:\n",
    "    repo_id_candidate = f\"{owner}/{space}\"\n",
    "    print(\"Attempting to create Space under:\", repo_id_candidate)\n",
    "    try:\n",
    "        repo_url = api.create_repo(repo_id=repo_id_candidate, repo_type=\"space\", space_sdk=\"gradio\", exist_ok=True)\n",
    "        print(\"‚úÖ Space created/existed at:\", repo_url)\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå create_repo failed:\", repr(e))\n",
    "        # If response object available, show details to help debugging\n",
    "        try:\n",
    "            resp = getattr(e, \"response\", None)\n",
    "            if resp is not None:\n",
    "                print(\"HTTP status:\", getattr(resp, \"status_code\", \"N/A\"))\n",
    "                print(\"Response text:\", getattr(resp, \"text\", \"N/A\"))\n",
    "        except Exception:\n",
    "            pass\n",
    "        print(\"\\nCommon causes:\")\n",
    "        print(\" - Token does not have write/admin scopes (check https://huggingface.co/settings/tokens).\")\n",
    "        print(\" - Token belongs to a different user than `owner` (create repo under that user's namespace).\")\n",
    "        print(\" - You're trying to create a Space in an organization where you lack permissions.\")\n",
    "        print(\"\\nSuggested next steps:\")\n",
    "        print(\" - Verify the token scopes and regenerate a token with 'repo' and 'write' scopes.\")\n",
    "        print(\" - If the token belongs to another account, use that account's username for repo_id.\")\n",
    "        print(\" - As a quick check, try creating a repo without explicit repo_id to let HF pick your user:\")\n",
    "        print(\"    api.create_repo(repo_type='space', space_sdk='gradio', exist_ok=True)\")\n",
    "else:\n",
    "    print(\"Cannot proceed: owner unknown. Ensure HF token is set and valid in `token`.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c68ed77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà</td></tr><tr><td>train_acc</td><td>‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train_loss</td><td>‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val_acc</td><td>‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá</td></tr><tr><td>val_loss</td><td>‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>train_acc</td><td>45.065</td></tr><tr><td>train_loss</td><td>2.39028</td></tr><tr><td>val_acc</td><td>54.7</td></tr><tr><td>val_loss</td><td>1.89943</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">skilled-music-5</strong> at: <a href='https://wandb.ai/142402007-indian-institute-of-technology-palakkad/Kundan_ass_6/runs/25weoali' target=\"_blank\">https://wandb.ai/142402007-indian-institute-of-technology-palakkad/Kundan_ass_6/runs/25weoali</a><br> View project at: <a href='https://wandb.ai/142402007-indian-institute-of-technology-palakkad/Kundan_ass_6' target=\"_blank\">https://wandb.ai/142402007-indian-institute-of-technology-palakkad/Kundan_ass_6</a><br>Synced 4 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251110_222413-25weoali/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sumanp/Assignment-5/wandb/Kundan_assign_6/wandb/run-20251110_223900-gabdvjiv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/142402007-indian-institute-of-technology-palakkad/drifted/runs/gabdvjiv' target=\"_blank\">baseline-run</a></strong> to <a href='https://wandb.ai/142402007-indian-institute-of-technology-palakkad/drifted' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/142402007-indian-institute-of-technology-palakkad/drifted' target=\"_blank\">https://wandb.ai/142402007-indian-institute-of-technology-palakkad/drifted</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/142402007-indian-institute-of-technology-palakkad/drifted/runs/gabdvjiv' target=\"_blank\">https://wandb.ai/142402007-indian-institute-of-technology-palakkad/drifted/runs/gabdvjiv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/142402007-indian-institute-of-technology-palakkad/drifted/runs/gabdvjiv?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fd1a0833210>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "import wandb\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Re-initialize W&B run for Q3\n",
    "wandb.init(project=\"drifted\",\n",
    "           name=\"baseline-run\",\n",
    "           config={\"epochs\": 1, \"batch_size\": 16, \"model\": \"ResNet18\"},\n",
    "           reinit=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a736bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:03<00:00, 12.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Baseline Accuracy: 54.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>baseline_acc</td><td>‚ñÅ</td></tr><tr><td>baseline_loss</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>baseline_acc</td><td>54.7</td></tr><tr><td>baseline_loss</td><td>1.90393</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">baseline-run</strong> at: <a href='https://wandb.ai/142402007-indian-institute-of-technology-palakkad/drifted/runs/gabdvjiv' target=\"_blank\">https://wandb.ai/142402007-indian-institute-of-technology-palakkad/drifted/runs/gabdvjiv</a><br> View project at: <a href='https://wandb.ai/142402007-indian-institute-of-technology-palakkad/drifted' target=\"_blank\">https://wandb.ai/142402007-indian-institute-of-technology-palakkad/drifted</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251110_223900-gabdvjiv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load your trained model weights\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# normal (clean) validation loader already defined as val_loader\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def evaluate_model(model, dataloader, desc=\"eval\"):\n",
    "    model.eval()\n",
    "    correct, total, loss_val = 0, 0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(dataloader, desc=desc):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            out = model(imgs)\n",
    "            loss = criterion(out, labels)\n",
    "            loss_val += loss.item()\n",
    "            _, preds = out.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "    acc = 100 * correct / total\n",
    "    return acc, loss_val / len(dataloader)\n",
    "\n",
    "baseline_acc, baseline_loss = evaluate_model(model, val_loader, desc=\"Baseline Validation\")\n",
    "\n",
    "wandb.log({\"baseline_acc\": baseline_acc, \"baseline_loss\": baseline_loss})\n",
    "print(f\"‚úÖ Baseline Accuracy: {baseline_acc:.2f}%\")\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b88880de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drifted transform (simulate brightness shift + noise)\n",
    "drift_transform = transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.CenterCrop(128),\n",
    "    transforms.ColorJitter(brightness=1.5, contrast=1.5),  # drift in brightness/contrast\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x + 0.05 * torch.randn_like(x)),  # add Gaussian noise\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "# New dataset with drift\n",
    "val_data_drift = datasets.ImageFolder(val_dir, transform=drift_transform)\n",
    "val_loader_drift = torch.utils.data.DataLoader(val_data_drift, batch_size=16, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "234385a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sumanp/Assignment-5/wandb/Kundan_assign_6/wandb/run-20251110_223920-3wzhef6e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/142402007-indian-institute-of-technology-palakkad/tiny-imagenet-drift-detection/runs/3wzhef6e' target=\"_blank\">drifted-run</a></strong> to <a href='https://wandb.ai/142402007-indian-institute-of-technology-palakkad/tiny-imagenet-drift-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/142402007-indian-institute-of-technology-palakkad/tiny-imagenet-drift-detection' target=\"_blank\">https://wandb.ai/142402007-indian-institute-of-technology-palakkad/tiny-imagenet-drift-detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/142402007-indian-institute-of-technology-palakkad/tiny-imagenet-drift-detection/runs/3wzhef6e' target=\"_blank\">https://wandb.ai/142402007-indian-institute-of-technology-palakkad/tiny-imagenet-drift-detection/runs/3wzhef6e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Drifted Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [00:06<00:00, 101.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Drifted Accuracy: 12.22%\n",
      "üö® W&B alert triggered!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>baseline_acc</td><td>‚ñÅ</td></tr><tr><td>drifted_acc</td><td>‚ñÅ</td></tr><tr><td>drifted_loss</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>baseline_acc</td><td>54.7</td></tr><tr><td>drifted_acc</td><td>12.22</td></tr><tr><td>drifted_loss</td><td>5.53426</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">drifted-run</strong> at: <a href='https://wandb.ai/142402007-indian-institute-of-technology-palakkad/tiny-imagenet-drift-detection/runs/3wzhef6e' target=\"_blank\">https://wandb.ai/142402007-indian-institute-of-technology-palakkad/tiny-imagenet-drift-detection/runs/3wzhef6e</a><br> View project at: <a href='https://wandb.ai/142402007-indian-institute-of-technology-palakkad/tiny-imagenet-drift-detection' target=\"_blank\">https://wandb.ai/142402007-indian-institute-of-technology-palakkad/tiny-imagenet-drift-detection</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251110_223920-3wzhef6e/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=\"tiny-imagenet-drift-detection\",\n",
    "           name=\"drifted-run\",\n",
    "           config={\"drift_type\": \"brightness+noise\"},\n",
    "           reinit=True)\n",
    "\n",
    "drifted_acc, drifted_loss = evaluate_model(model, val_loader_drift, desc=\"Drifted Validation\")\n",
    "\n",
    "wandb.log({\n",
    "    \"drifted_acc\": drifted_acc,\n",
    "    \"drifted_loss\": drifted_loss,\n",
    "    \"baseline_acc\": baseline_acc\n",
    "})\n",
    "print(f\"‚ö†Ô∏è Drifted Accuracy: {drifted_acc:.2f}%\")\n",
    "\n",
    "# Alert if drop > threshold\n",
    "threshold = baseline_acc * 0.8   # e.g., 20% drop allowed\n",
    "if drifted_acc < threshold:\n",
    "    wandb.alert(\n",
    "        title=\"‚ö†Ô∏è Accuracy Drop Detected!\",\n",
    "        text=f\"Drifted accuracy {drifted_acc:.2f}% below threshold {threshold:.2f}%\",\n",
    "        level=wandb.AlertLevel.WARN\n",
    "    )\n",
    "    print(\" W&B alert triggered!\")\n",
    "else:\n",
    "    print(\" Accuracy within acceptable range.\")\n",
    "\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276fabab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "awa2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
